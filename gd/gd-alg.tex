\documentclass{article}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{nopageno}

\begin{document}

% ---------------------------
% Full-batch Gradient Descent
% ---------------------------
\begin{algorithm*}
\caption{Gradient Descent($\theta_{\text{init}}, \eta, J, \epsilon$)}
\label{alg:gradient-descent}
\begin{algorithmic}[1]
\STATE Initialize $\theta^{(0)} = \theta_{\text{init}}$
\STATE Initialize $t = 0$
\REPEAT
  \STATE $t = t + 1$
  \STATE $\theta^{(t)} = \theta^{(t-1)} - \eta \nabla_\theta J(\theta^{(t-1)})$
\UNTIL{$\left| J(\theta^{(t)}) - J(\theta^{(t-1)}) \right| < \epsilon$}
\RETURN $\theta^{(t)}$
\end{algorithmic}
\end{algorithm*}

\clearpage

% ---------------------------
% Stochastic Gradient Descent
% ---------------------------
\begin{algorithm*}
\caption{Stochastic Gradient Descent($\theta_{\text{init}}, \eta, \{J_i\}_{i=1}^n, \epsilon$)}
\label{alg:stochastic-gradient-descent}
\begin{algorithmic}[1]
\STATE Initialize $\theta^{(0)} = \theta_{\text{init}}$
\STATE Initialize $t = 0$
\REPEAT
  \STATE $t = t + 1$
  \STATE $i = \text{randomly sample from } \{1, \ldots, n\}$
  \STATE $\theta^{(t)} = \theta^{(t-1)} - \eta \nabla_\theta J_i(\theta^{(t-1)})$
\UNTIL{$\left| J(\theta^{(t)}) - J(\theta^{(t-1)}) \right| < \epsilon$}
\RETURN $\theta^{(t)}$
\end{algorithmic}
\end{algorithm*}

\clearpage

% ---------------------------
% Mini-batch Gradient Descent
% ---------------------------
\begin{algorithm*}
\caption{Mini-batch Gradient Descent($\theta_{\text{init}}, \eta, b, \{J_i\}_{i=1}^n, \epsilon$)}
\label{alg:mini-batch-gradient-descent}
\begin{algorithmic}[1]
\STATE Initialize $\theta^{(0)} = \theta_{\text{init}}$
\STATE Initialize $t = 0$
\REPEAT
  \STATE $t = t + 1$
  \STATE $B = \text{random mini-batch of size } b \text{ from } \{1, \ldots, n\}$
  \STATE $\theta^{(t)} = \theta^{(t-1)} - \eta \nabla_\theta J_B(\theta^{(t-1)})$
\UNTIL{$\left| J(\theta^{(t)}) - J(\theta^{(t-1)}) \right| < \epsilon$}
\RETURN $\theta^{(t)}$
\end{algorithmic}
\end{algorithm*}

\end{document}